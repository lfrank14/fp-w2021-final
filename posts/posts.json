[
  {
    "path": "posts/data-cleaning-with-purrr/",
    "title": "Data cleaning with {purrr}",
    "description": "A tutorial for using {purrr} for data cleaning.",
    "author": [
      {
        "name": "Lea Frank",
        "url": {}
      }
    ],
    "date": "2021-06-11",
    "categories": [
      "map",
      "map_df",
      "map2"
    ],
    "contents": "\n\nContents\nBatch Loading\nCreate a list with the file paths\nUse purrr::map to read files\n\nData cleaning\nMy final solution\n\nThe {purrr} package provides a number of helpful functions for loading in multiple data files and iterating data processing steps over multiple data frames. This tutorial will provide step-by-step instructions that how just how powerful the map family of functions can be.\nBatch Loading\nThe original data files downloaded from the NHANES website were separated by year and data type (i.e. demographics and FSQ), resulting in a number of data files. Rather than loading in each file one at a time, the purrr::map family of functions provides powerful tools for loading in large amounts of data.\nCreate a list with the file paths\nThe here::here function is first used to define the path to the data files.\n\n\n(rootpath <- here::here(\"data\"))\n\n\n[1] \"/Users/daniel/Desktop/fp-w2021-final/data\"\n\nThe dir_ls function from the {fs} package creates a vector of the paths for the files listed within rootpath.\n\n\nfnames <- fs::dir_ls(rootpath)\nhead(fnames)\n\n\n/Users/daniel/Desktop/fp-w2021-final/data/DEMO_1999-2000.XPT\n/Users/daniel/Desktop/fp-w2021-final/data/DEMO_2001-2002.XPT\n/Users/daniel/Desktop/fp-w2021-final/data/DEMO_2003-2004.XPT\n/Users/daniel/Desktop/fp-w2021-final/data/DEMO_2005-2006.XPT\n/Users/daniel/Desktop/fp-w2021-final/data/DEMO_2007-2008.XPT\n/Users/daniel/Desktop/fp-w2021-final/data/DEMO_2009-2010.XPT\n\nImportantly, this vector is named with the associated paths. That is, each element of the vector is attributed a name that is also a character string of the file path. I know this sounds like redundant information, but it actually comes in handy when using map_df as shown below.\n\n\nnames(head(fnames))\n\n\n[1] \"/Users/daniel/Desktop/fp-w2021-final/data/DEMO_1999-2000.XPT\"\n[2] \"/Users/daniel/Desktop/fp-w2021-final/data/DEMO_2001-2002.XPT\"\n[3] \"/Users/daniel/Desktop/fp-w2021-final/data/DEMO_2003-2004.XPT\"\n[4] \"/Users/daniel/Desktop/fp-w2021-final/data/DEMO_2005-2006.XPT\"\n[5] \"/Users/daniel/Desktop/fp-w2021-final/data/DEMO_2007-2008.XPT\"\n[6] \"/Users/daniel/Desktop/fp-w2021-final/data/DEMO_2009-2010.XPT\"\n\nThe demographics and FSQ will be loaded separately since they will require different data cleaning steps. Regular expression can be used with the fs::dir_ls function to filter files that match a specific pattern.\n\n\n# list file paths for files that contain the pattern \"DEMO\"\ndemo_paths <- dir_ls(rootpath, regexp = \"DEMO\")\n\n# list file paths for files that contain the pattern \"FSQ\"\nfsq_paths <- dir_ls(rootpath, regexp = \"FSQ\")\n\n\n\nUse purrr::map to read files\nThe purrr::map family of functions allows us to iterate a function over elements of a list or vector. In this case, we want to use rio::import to read in the data files using the vectors of file paths.\nThere are two ways in which we can read in the data. The first option is to use the purrr::map function to read each data frame into a separate element of a list. This can be useful if you want to use map to iteration the same functions, like data cleaning, over each data frame.\n\n\n# Loading the data files into separate lists\ndemos_list <- map(demo_paths, rio::import)\nfsq_list <- map(demo_paths, rio::import)\n\n\n\nAnother option is to use purrr::map_df to read each data file into a single data frame. Importantly, this function allows you to specify the .id, which will create a variable to identify each iteration of the function. As I mentioned earlier, the fs::dir_ls function will assign names to each path. Using map_df on the named list of paths will generate a column in the data frame output that assigns the path name to each iteration of rio::import.\n\n\n# Loading the data files into a single data frame\ndemos <- map_dfr(demo_paths, rio::import, .id = \"file\")\nkable(head(demos[,1:4]))\n\n\nfile\nSEQN\nSDDSRVYR\nRIDSTATR\n/Users/daniel/Desktop/fp-w2021-final/data/DEMO_1999-2000.XPT\n1\n1\n2\n/Users/daniel/Desktop/fp-w2021-final/data/DEMO_1999-2000.XPT\n2\n1\n2\n/Users/daniel/Desktop/fp-w2021-final/data/DEMO_1999-2000.XPT\n3\n1\n2\n/Users/daniel/Desktop/fp-w2021-final/data/DEMO_1999-2000.XPT\n4\n1\n2\n/Users/daniel/Desktop/fp-w2021-final/data/DEMO_1999-2000.XPT\n5\n1\n2\n/Users/daniel/Desktop/fp-w2021-final/data/DEMO_1999-2000.XPT\n6\n1\n2\n\nfsq <- map_dfr(fsq_paths, rio::import, .id = \"file\")\nkable(head(fsq[,1:4]))\n\n\nfile\nSEQN\nFSD010\nFSD160\n/Users/daniel/Desktop/fp-w2021-final/data/FSQ_1999-2000.XPT\n1\n1\n1\n/Users/daniel/Desktop/fp-w2021-final/data/FSQ_1999-2000.XPT\n2\n1\n2\n/Users/daniel/Desktop/fp-w2021-final/data/FSQ_1999-2000.XPT\n3\n1\n2\n/Users/daniel/Desktop/fp-w2021-final/data/FSQ_1999-2000.XPT\n4\n2\n1\n/Users/daniel/Desktop/fp-w2021-final/data/FSQ_1999-2000.XPT\n5\n1\n2\n/Users/daniel/Desktop/fp-w2021-final/data/FSQ_1999-2000.XPT\n6\n1\n2\n\nWhile both options are valid, which one you choose will ultimately depend on what you intend to do with the output. If I wanted to keep the data frames separated by year so I could more easily process and analyze the data, map would might be the better approach.\nIf I wanted to create a single data file that contains survey data from all years (1999-2016) that could then be shared with collaborators, I might choose to use map_dfr to create a single data frame. This option is demonstrated below in My Final Solution.\nLet’s take a look at how map can be used to iterate data cleaning steps over a list of data frames.\nData cleaning\nLet’s start with the list of data frames for the demographics surveys (demos_list). Each element of the list contains the demographics survey data for a specific year range (e.g. 1999-2000 or 2013-2014). If we want to apply the same data cleaning steps to each data frame, we can use map to iterate those data cleaning functions to each element of the list.\nFirst, let’s start by creating a variable in each data frame for the year. For this step, we can use map2 to iterate through the file paths (demo_paths) and list of data frames (demos_list) in parallel. The year will be extracted from the file path and applied to the corresponding data frame.\nThis time, rather than using an existing function, we can create our own. When writing a function to use within the map functions, it must be wrapped within the curly brackets ~{ [some custom function] }. To call each input, you would use .x (for the first input, demo_paths) and .y (for the second input, demos_list).\n\n\ndemos_list_clean <- map2(demo_paths, demos_list, ~{\n  # create a new variable in demos_list for th year\n  .y %>% \n    mutate(year = str_extract(.x, \"\\\\d{4}-\\\\d{4}\")) \n                  # extracts the pattern that matches: 4 digits-4 digits (e.g. 2001-2002)\n})\n\nkable(head(demos_list_clean[[1]][\"year\"]))\n\n\nyear\n1999-2000\n1999-2000\n1999-2000\n1999-2000\n1999-2000\n1999-2000\n\nNext, I want to select the variables of interest and rename them to something more clear. This time, I will need to return the data frame in order for it to save in the output.\n\n\ndemos_list_clean <- map(demos_list_clean, ~{\n  # selecting variables of interest\n  .x <- .x %>% \n    select(year, SEQN, RIDAGEYR, RIAGENDR, \n         RIDRETH1, DMDEDUC2, DMDEDUC3)\n  \n  # renaming the columns\n  names(.x) <- c(\"year\", \"id\",\"age\",\"gender\",\n                  \"race_ethnic\",\"educ_adult\",\"educ_child\")\n  \n  # return the new .x\n  return(.x)\n})\n\nkable(head(demos_list_clean[[1]]))\n\n\nyear\nid\nage\ngender\nrace_ethnic\neduc_adult\neduc_child\n1999-2000\n1\n2\n2\n4\nNA\nNA\n1999-2000\n2\n77\n1\n3\n5\nNA\n1999-2000\n3\n10\n2\n3\nNA\n3\n1999-2000\n4\n1\n1\n4\nNA\nNA\n1999-2000\n5\n49\n1\n3\n5\nNA\n1999-2000\n6\n19\n2\n5\nNA\n15\n\nFinally, I may want to convert some of the categorical variables into factors and add labels to the different levels.\n\n\ndemos_list_clean <- map(demos_list_clean, ~{\n  \n  # create new factors for gender and race/ethnicity\n  .x %>% \n    mutate(gender = factor(gender, labels = c(\"male\",\"female\")),\n           race_ethnic = factor(race_ethnic, labels = c(\"mexican-american\",\n                                                        \"other-hispanic\",\n                                                        \"non-hispanic-white\",\n                                                        \"non-hispanic-black\",\n                                                        \"other-race\")))\n})\n\nkable(head(demos_list_clean[[1]]))\n\n\nyear\nid\nage\ngender\nrace_ethnic\neduc_adult\neduc_child\n1999-2000\n1\n2\nfemale\nnon-hispanic-black\nNA\nNA\n1999-2000\n2\n77\nmale\nnon-hispanic-white\n5\nNA\n1999-2000\n3\n10\nfemale\nnon-hispanic-white\nNA\n3\n1999-2000\n4\n1\nmale\nnon-hispanic-black\nNA\nNA\n1999-2000\n5\n49\nmale\nnon-hispanic-white\n5\nNA\n1999-2000\n6\n19\nfemale\nother-race\nNA\n15\n\nThese steps can all be combined to produce the following code:\n\n\ndemos_list_clean <- map2(demo_paths, demos_list, ~{\n  .y <- .y %>% \n    mutate(year = str_extract(.x, \"\\\\d{4}-\\\\d{4}\"),\n           RIAGENDR = factor(RIAGENDR, labels = c(\"male\",\"female\")),\n           RIDRETH1 = factor(RIDRETH1, labels = c(\"mexican-american\",\n                                                        \"other-hispanic\",\n                                                        \"non-hispanic-white\",\n                                                        \"non-hispanic-black\",\n                                                        \"other-race\"))) %>% \n    select(year, SEQN, RIDAGEYR, RIAGENDR, \n         RIDRETH1, DMDEDUC2, DMDEDUC3)\n  names(.y) <- c(\"year\", \"id\",\"age\",\"gender\",\n                  \"race_ethnic\",\"educ_adult\",\"educ_child\")\n  return(.y)\n})\n\n\n\nMy final solution\nAs I mentioned earlier, another possible route was to read the data files into a single data frame. Since the output was intended to be shared with collaborators on this blog, I decided this was the optimal solution. The same data cleaning steps conducted above can then be applied to the single data frame.\n\n\ndemos <- dir_ls(rootpath, \n                 regexp = \"DEMO\") %>% # listing demographics files\n  # batch loading demographics files\n  map_dfr(rio::import, .id = \"file\") %>% \n                       # .id = \"file\" creates a variable with the file name\n  # creating a variable for year from the file name id\n  mutate(year = str_extract(file, \"\\\\d{4}-\\\\d{4}\"), \n         # creating factors for gender and race/ethnicity \n         RIAGENDR = factor(RIAGENDR, labels = c(\"male\",\"female\")),\n         RIDRETH1 = factor(RIDRETH1, labels = c(\"mexican-american\",\n                                                \"other-hispanic\",\n                                                \"non-hispanic-white\",\n                                                \"non-hispanic-black\",\n                                                \"other-race\"))) %>% \n  # selecting variables of interest\n  select(year, SEQN, RIDAGEYR, RIAGENDR, \n         RIDRETH1, DMDEDUC2, DMDEDUC3)\n\n# renaming the columns into something more legible\nnames(demos) <- c(\"year\", \"id\",\"age\",\"gender\",\n                  \"race_ethnic\",\"educ_adult\",\"educ_child\") \n\nfsq <- dir_ls(rootpath, \n                 regexp = \"FSQ\") %>% # listing questionnaire files\n  # batch importing questionnaire files\n  map_dfr(rio::import, .id = \"file\") %>% \n                       # .id = \"file\" creates a variable with the file name\n  # creating new variables for year and food security\n  mutate(year = str_extract(file, \"\\\\d{4}-\\\\d{4}\"), \n         hh_food_secure = ifelse(year == \"1999-2000\" | year == \"2001-2002\", \n                                 HHFDSEC, FSDHH)) %>% \n  # selecting variables of interest\n  select(year, SEQN, hh_food_secure) \n\n# renaming the 'SEQN' column so that it can be joined with the demographics data\nnames(fsq)[2] <- \"id\" \n\n\n\nAfter creating data frames for the demographics and FSQ data, they were then joined by the year and id.\n\n\ndf <- left_join(demos, fsq)\nkable(head(df))\n\n\nyear\nid\nage\ngender\nrace_ethnic\neduc_adult\neduc_child\nhh_food_secure\n1999-2000\n1\n2\nfemale\nnon-hispanic-black\nNA\nNA\n1\n1999-2000\n2\n77\nmale\nnon-hispanic-white\n5\nNA\n1\n1999-2000\n3\n10\nfemale\nnon-hispanic-white\nNA\n3\n1\n1999-2000\n4\n1\nmale\nnon-hispanic-black\nNA\nNA\n4\n1999-2000\n5\n49\nmale\nnon-hispanic-white\n5\nNA\n1\n1999-2000\n6\n19\nfemale\nother-race\nNA\n15\n1\n\nFinally, the data frame was saved into a single .csv file that could then be shared with collaborators.\n\n\nwrite_csv(df, str_c(rootpath,\"/nhanes_1999-2016.csv\"))\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-11T09:45:07-07:00",
    "input_file": {}
  },
  {
    "path": "posts/parallel-iteration/",
    "title": "Parallel Iteration",
    "description": "Using `nest` with `map2_*` or `pmap_*` in `{purrr}`.",
    "author": [
      {
        "name": "Wanjia Guo",
        "url": {}
      }
    ],
    "date": "2021-05-20",
    "categories": [
      "nest",
      "map2",
      "pmap"
    ],
    "contents": "\n\nContents\nIntro\nsplit vs. nest\nfirst figure\npmap_*\nmap2_*\n\nIntro\nIn this post, we will dive deeper into the {purrr} package. We will explore purrr::nest() %>% dplyr::mutate(), which is an alternative to the split() function in the base-R. Moreover, we will see how the combination of purrr::nest() %>% dplyr::mutate() with purrr::map2_*() or purrr::pmap_*() can be a powerful tool in functional programming.\nThe data we are going to use was narrowed down to the following variables of interest for the current post. For more information about data, please checkout here.\n\nVariable Code\nType\nDescription\nyear\nString\nThe year that data was collected\nid\nInteger\nRespondent ID\nage\nInteger\nAge in years at screening\ngender\nCategory\nGender: male or female\nrace_ethnic\nCategory\nRace/Hispanic origin: mexican-american, non-hispanic-black, non-hispanic-white, other-hispanic, other-race\nhh_food_secure\nInteger\nHousehold food security category over last 12 months\nage_group\nBinary\nAge group: adult(20+) or child(6-19)\neduc\nInteger\nEducation level for adults 20+ and children/youth 6-19\n\nLet’s take a look at the dataframe.\n\n\nhead(df)\n\n\n# A tibble: 6 x 8\n  year         id   age gender race_ethnic        hh_food_secure\n  <chr>     <dbl> <dbl> <fct>  <fct>                       <dbl>\n1 1999-2000     2    77 male   non-hispanic-white              1\n2 1999-2000     3    10 female non-hispanic-white              1\n3 1999-2000     5    49 male   non-hispanic-white              1\n4 1999-2000     6    19 female other-race                      1\n5 1999-2000     8    13 male   non-hispanic-white              1\n6 1999-2000     9    11 female non-hispanic-black              2\n# … with 2 more variables: age_group <fct>, educ <dbl>\n\nsplit vs. nest\nWe are interested in how food security changes over time, separated by gender and age group (child and adult). For the first step, we want to split the dataframe into lists with split as the following. However, the three grouping variables (gender, age group, and year) are merged together into one column. This is less desirable because we will need each of these variables for later.\n\n\nsplit_df = split(df, list(df$gender, df$age_group, df$year))\n\nhead(split_df$`female.adult.1999-2000`)\n\n\n# A tibble: 6 x 8\n  year         id   age gender race_ethnic        hh_food_secure\n  <chr>     <dbl> <dbl> <fct>  <fct>                       <dbl>\n1 1999-2000    15    38 female non-hispanic-white              1\n2 1999-2000    16    85 female non-hispanic-black              4\n3 1999-2000    20    23 female mexican-american                1\n4 1999-2000    24    53 female non-hispanic-white              1\n5 1999-2000    25    42 female non-hispanic-white              1\n6 1999-2000    34    38 female non-hispanic-black              3\n# … with 2 more variables: age_group <fct>, educ <dbl>\n\nEquivalently, we can also use nest from the {purrr} package as the following:\n\n\nnest_df = df %>% \n  group_by(year, age_group, gender) %>% \n  nest()\n\nhead(nest_df)\n\n\n# A tibble: 6 x 4\n# Groups:   year, gender, age_group [6]\n  year      gender age_group data                \n  <chr>     <fct>  <fct>     <list>              \n1 1999-2000 male   adult     <tibble [2,211 × 5]>\n2 1999-2000 female child     <tibble [1,698 × 5]>\n3 1999-2000 male   child     <tibble [1,744 × 5]>\n4 1999-2000 female adult     <tibble [2,534 × 5]>\n5 2001-2002 male   adult     <tibble [2,384 × 5]>\n6 2001-2002 female adult     <tibble [2,669 × 5]>\n\nThese two approaches end with very similar results, except gender, age_group, and year are maintained with its original structure with nest() but not with split().\nMoreover, with nest(), we can manipulate the data frame within each row while save the output as another column. We will calculate within each gender, age group and year, how food security changes with age. (If you find the map() function confusing, I encourage you take a look at this post.)\n\n\nmodel_df = nest_df %>% \n  mutate(n = map_dbl(data, nrow),\n         m1 = map(data, ~lm(hh_food_secure ~ age, data = .x)),\n         coefs = map(m1, coef),\n         intercept = map_dbl(coefs, 1),\n         slope = map_dbl(coefs, 2))\n\nhead(model_df)\n\n\n# A tibble: 6 x 9\n# Groups:   year, gender, age_group [6]\n  year      gender age_group data            n m1     coefs  intercept\n  <chr>     <fct>  <fct>     <list>      <dbl> <list> <list>     <dbl>\n1 1999-2000 male   adult     <tibble [2…  2211 <lm>   <dbl …  1.599724\n2 1999-2000 female child     <tibble [1…  1698 <lm>   <dbl …  1.573725\n3 1999-2000 male   child     <tibble [1…  1744 <lm>   <dbl …  1.691323\n4 1999-2000 female adult     <tibble [2…  2534 <lm>   <dbl …  1.582938\n5 2001-2002 male   adult     <tibble [2…  2384 <lm>   <dbl …  1.752420\n6 2001-2002 female adult     <tibble [2…  2669 <lm>   <dbl …  1.703107\n# … with 1 more variable: slope <dbl>\n\nfirst figure\nLet’s take a look at how the slope change with time:\n\n\nmodel_df %>% \n  ggplot(aes(x = year, y = slope, color = age_group, group = age_group)) + \n  geom_line(size = 1.5) + \n  facet_wrap(~gender, nrow = 2) +\n  theme(legend.position = 'bottom') + \n  labs(y = 'Slope: Age and Food Security',\n       x = 'Year',\n       color = 'Age Group')\n\n\n\n\nFrom the figure, we can see that for adults, the slope is consistently negative across all time. In other words, as people age, the food security score decreased. However, for children, the food security increased dramatically recently, especially since 2010s. What if we want to dig deeper and see how age influences children’s food security within each year for different gender?\nLet’s start with only one row of data:\n\n\nchild_model_df = model_df %>% filter(age_group == 'child')\n\nplotting <- function(df, gender, year = NULL){\n  \n  p = df %>% \n    group_by(age, race_ethnic) %>% \n    summarise(m = mean(hh_food_secure),\n              sd = sd(hh_food_secure)) %>% \n    ggplot(aes(x=age,\n               y=m,\n               color = race_ethnic))+\n    geom_line(alpha = 0.7, size = 1.5) +\n    theme(legend.position = 'bottom')+\n    labs(x = 'Age',\n         y = 'Food Secure Score',\n         color = 'Race and Ethnic') + \n    guides(color=guide_legend(nrow=2, byrow=TRUE))\n  \n  if(missing(year)){\n    p = p + labs(title = gender)\n  }else{\n    p = p + labs(title = paste(year, gender, sep = \": \"))}\n\n  p\n  \n  }\n\n# make sure the funtion works for one row of data.\nplotting(child_model_df$data[[1]], \n         child_model_df$gender[[1]], \n         child_model_df$year[[1]])\n\n\n\n\npmap_*\nWith pmap_*, we can easily use the above code to produce figures for each row. When using pmap_*, the first input is a list of column names that we need from the dataframe and the second input is the plotting function we used in the last part. The ..1, ..2, and ..3 are corresponding to data, gender, and year. Then, Voila, you have a figure for data from each row!\n\n\nchild_model_plot_df <- child_model_df %>% \n  mutate(nest_plot = pmap(list(data, gender, year),\n                          ~{plotting(..1, ..2, ..3)})\n                          )\n\nggpubr::ggarrange(child_model_plot_df$nest_plot[[1]],\n                  child_model_plot_df$nest_plot[[2]],\n                  child_model_plot_df$nest_plot[[17]],\n                  child_model_plot_df$nest_plot[[18]],\n                  ncol = 2, nrow = 2,\n                  common.legend = TRUE,\n                  legend = 'bottom')\n\n\n\n\nAnother cool thing about nest, is that we can easily reverse this process with unnest after we finished our grouped analysis.\n\n\nadult_df = model_df %>% \n  filter(age_group == 'adult') %>%\n  select(year, gender, age_group, data) %>% unnest(data)\nhead(adult_df)\n\n\n# A tibble: 6 x 8\n# Groups:   year, gender, age_group [1]\n  year      gender age_group    id   age race_ethnic       \n  <chr>     <fct>  <fct>     <dbl> <dbl> <fct>             \n1 1999-2000 male   adult         2    77 non-hispanic-white\n2 1999-2000 male   adult         5    49 non-hispanic-white\n3 1999-2000 male   adult        12    37 non-hispanic-white\n4 1999-2000 male   adult        13    70 mexican-american  \n5 1999-2000 male   adult        14    81 non-hispanic-white\n6 1999-2000 male   adult        29    62 non-hispanic-white\n# … with 2 more variables: hh_food_secure <dbl>, educ <dbl>\n\nmap2_*\nLastly, once we learned about pmap_*, map2_* is very similar. Instead of being able to use as many variables you need with pmap, map2 is specialized for only 2 inputs. Let’s see an example below. Since we have found that the relationship between age and food security are pretty consistent over the years, let’s make a plot that ignore the age factor with map2.\n\n\nadult_plot_df = adult_df %>% \n  group_by(gender) %>% \n  nest() %>% \n  mutate(nest_plot = map2(data, gender,\n                          ~plotting(.x, .y)))\n\nggpubr::ggarrange(adult_plot_df$nest_plot[[1]],\n                  adult_plot_df$nest_plot[[2]],\n                  ncol = 2,\n                  common.legend = TRUE,\n                  legend = 'bottom')\n\n\n\n\n\n\n\n",
    "preview": "posts/parallel-iteration/parallel-iteration_files/figure-html5/unnamed-chunk-5-1.png",
    "last_modified": "2021-06-11T13:34:09-07:00",
    "input_file": {},
    "preview_width": 1920,
    "preview_height": 1152
  },
  {
    "path": "posts/looping/",
    "title": "Looping",
    "description": "A tutorial for using {purrr} for looping functions.",
    "author": [
      {
        "name": "Meg Siritzky",
        "url": {}
      }
    ],
    "date": "2021-05-13",
    "categories": [
      "map",
      "map_dbl",
      "nest",
      "pmap",
      "walk2"
    ],
    "contents": "\n\nContents\nBackground\nDataset\nTheoretical Background & Research Question\nReferences\n\nUsing {purrr}\nData cleaing\nUsing map and map_dbl functions\nCreating plots using pmap() and list()\nExporting plots using walk2 function\n\n\nIn this post, we will use the {purrr} package to loop through functions in a data frame. We will look at purrr::map() and purrr:map_dbl(), which can iterate functions over multiple elements of a vector or list. We will also explore walk2 as an alternative to map2.\nBackground\nDataset\nFor this post, we’ll be using data from the National Health and Nutrition Examination Survey (NHANES), which provides longitudinal data on health and nutrition in the United States. More information about the dataset is available here.\nTheoretical Background & Research Question\nResearch has found a negative relation between educational attainment and food insecurity - that is, individuals who have received more education also experience greater food security (Mutisya et al., 2016). However, this relationship could be attributed to a number of factors, including inequitable access to education across SES groups and the inclusion of food literacy education in schooling (American Psychological Association, 2017; Begley, Paynter, Butcher, & Dhaliwal, 2019; Hochschild, 2003; Zhang, 2003). Thus, the relationship between educational attainment and food insecurity may change over time as public policy and education change.\nTo practice using the purrr:map() family of functions, we’re going to investigate the following research question: How does the relationship between educational attainment and food insecurity change over time?\nReferences\nAmerican Psychological Association. (2017). Education & Socioeconomic status. https://www.apa.org/pi/ses/resources/publications/factsheet-education.pdf\nBegley, A., Paynter, E., Butcher, L. M., & Dhaliwal, S. S. (2019). Examining the association between food literacy and food insecurity. Nutrients, 11(2), 445.\nHochschild, J. L. (2003). Social class in public schools. Journal of Social Issues, 59, 821-840.\nMutisya, M., Ngware, M.W., Kabiru, C.W. et al. The effect of education on household food security in two informal urban settlements in Kenya: a longitudinal analysis. Food Sec. 8, 743–756 (2016). https://doi.org/10.1007/s12571-016-0589-3\nZhang, M. (2003). Links between school absenteeism and child poverty. Pastoral Care in Education, 21, 10-17. doi:10.1111/1468-0122.00249\nUsing {purrr}\nWe’ll be looking at the variable of educ_adult to represent the level of educational attainment in the general population, and comparing that to a new variable we’ll create to represent the percentage of the total population experiencing food insecurity.\nFirst, let’s load the R packages we’ll be using\n\n\nlibrary(tidyverse)\nlibrary(repurrrsive)\nlibrary(rio)\nlibrary(here)\nlibrary(glue)\n\n\n\nThen we’ll load our data\n\n\nfi <- import(here(\"data\", \"nhanes_1999-2016.csv\"))\n\n\n\nData cleaing\nFirst, we’re going to convert our food insecurity variable hh_food_secure to a factor named security, rename the levels of the factor so they are meaningful, and remove any NAs in our variables of interest.\n\n\nfi_factor <- fi %>% \n  mutate(security = as_factor(hh_food_secure)) %>% \n  mutate(security = case_when(\n    security == \"1\" ~ \"full food security\",\n    security == \"2\" ~ \"marginal food security\",\n    security == \"3\" ~ \"low food security\",\n    security == \"4\" ~ \"very low food security\")) %>% \n  filter(security != is.na(security),\n         educ_adult != is.na(educ_adult))\n\n\n\nNow we’ll use group_by() from {dplyr} and the nest() function from the {purrr} package to create a nested data frame that groups our data by year and level of food insecurity. To learn more about using the nest() function, take a look at this post on parallel iteration. The data frame now looks like this:\n\n\nfi_grouped <- fi_factor %>% \n  group_by(year, security) %>% \n  nest()\nhead(fi_grouped)\n\n\n# A tibble: 6 x 3\n# Groups:   year, security [6]\n  year      security               data                \n  <chr>     <chr>                  <list>              \n1 1999-2000 full food security     <tibble [3,816 × 7]>\n2 1999-2000 very low food security <tibble [186 × 7]>  \n3 1999-2000 marginal food security <tibble [336 × 7]>  \n4 1999-2000 low food security      <tibble [407 × 7]>  \n5 2001-2002 full food security     <tibble [4,029 × 7]>\n6 2001-2002 marginal food security <tibble [356 × 7]>  \n\nRemember, we want to compare educational attainment to the percentage of the population experiencing food insecurity, so we need to create a variable that will tell us the percentage of the population that falls into each food security category at each time point. To do this, we’re going to first count the number of people in each food security category in each year (ct) and the population in each year (pop), and then create a new column called percent_insecurity that has the percentage of people in the population that report a given level of food security.\n\n\nfi_factor <- fi_factor %>% \n  add_count(year, name = \"pop\") %>% \n  add_count(year, security, name = \"ct\") %>% \n  dplyr::select(year, security, educ_adult, pop, ct) %>% \n  mutate(pop = as.numeric(pop),\n         ct = as.numeric(ct),\n         percent_insecurity = ct/pop)\nhead(fi_factor)\n\n\n       year           security educ_adult  pop   ct\n1 1999-2000 full food security          5 4745 3816\n2 1999-2000 full food security          5 4745 3816\n3 1999-2000 full food security          4 4745 3816\n4 1999-2000 full food security          1 4745 3816\n5 1999-2000 full food security          2 4745 3816\n6 1999-2000 full food security          5 4745 3816\n  percent_insecurity\n1           0.804215\n2           0.804215\n3           0.804215\n4           0.804215\n5           0.804215\n6           0.804215\n\nUsing map and map_dbl functions\nTo measure the the relationship between educational attainment and the percentage of the population experiencing food insecurity at each time point, we’re going to run a linear regression model for each food security category in each year. To do this, we’re first going to use the group_by() and nest() functions to create lists of data nested within each value of year and security.\nAfter the data are nested, we want to use the lm() function to run a linear regression model regressing percent_insecurity on educ_adult for each year/security combination. We’re going to use the map() function from the {purrr} package to accomplish this, iterating the lm() function across each combination of year and security (note, each “cell” in the data column is the data frame for the corresponding row listing the year/security combination).\nTo examine how the relationship changes over time, we want to compare the slopes across years for each food security category. To do this, we’re going to need the slopes. We can extract the slopes using the map_dbl() function. Why map_dbl() instead of map()? Because map() will give us the output in a list format, whereas map_dbl() will return an atomic vector of type double that we can save as a column in our data frame.\nBy using map_dbl(), we’re saving the data as type double. If we wanted to save the data as an integer vector instead, we could use map_int(). Alternatively, if we wanted to save the data as a character vector, we could use map_char().\nWe’re going to want to use our percent_insecurity variable later, so to move it from a nested list to the main data frame, we can unnest the data list and then use select from {dplyr} to save the columns we’re interested in.\n\n\nfi_lm <- fi_factor %>% \n  group_by(year, security) %>% \n  nest() %>% \n  mutate(m1 = map(data, ~lm(percent_insecurity ~ educ_adult, data = .x)),\n         coefs = map(m1, coefficients),\n         slope = map_dbl(coefs, 2)) %>% \n  unnest(data) %>% \n  dplyr::select(year, security, slope, percent_insecurity)\n\n\n\nUnnested, our data frame now looks like this:\n\n\nhead(fi_lm)\n\n\n# A tibble: 6 x 4\n# Groups:   year, security [1]\n  year      security                  slope percent_insecurity\n  <chr>     <chr>                     <dbl>              <dbl>\n1 1999-2000 full food security 1.181950e-15          0.8042150\n2 1999-2000 full food security 1.181950e-15          0.8042150\n3 1999-2000 full food security 1.181950e-15          0.8042150\n4 1999-2000 full food security 1.181950e-15          0.8042150\n5 1999-2000 full food security 1.181950e-15          0.8042150\n6 1999-2000 full food security 1.181950e-15          0.8042150\n\nCreating plots using pmap() and list()\nTo visualize the change in slope of how educational attainment predicts food insecurity across time, we can create a scatterplot for each food security category with an x-axis of year and a y-axis of slope. To create a plot for each food security category, we can use the pmap() and list() functions to create a new list in our nested data frame with a plot for each value of security. To learn more about using the pmap function, see this post. I’m using {.x} here in the title to customize each plot title to the food security category it corresponds to. I’m also including a custom function called scientific_10 developed here that will make the scientific notation in our y-axis easier to read.\n\n\nscientific_10 <- function(x) {\n  parse(text=gsub(\"e\", \" %*% 10^\", scales::scientific_format()(x)))\n}\n\nfi_plots <- fi_lm %>%\n  group_by(security) %>%\n  nest() %>%\n  mutate(plot = pmap(list(security, data), ~{\n    ggplot(..2, aes(year, slope)) +\n      geom_point() +\n      geom_line() +\n      labs(title = glue(\"Slope of relation between adult education levels and {.x} by year\"),\n           x = \"Year\",\n           y = \"Slope\") +\n      theme_minimal() +\n      theme(axis.text.x = element_text(angle = 90)) +\n      scale_y_continuous(labels = scientific_10)\n    })\n    )\n\n\n\nHere’s an example of one of the plots:\n\n\nfi_plots$plot[[2]]\n\n\n\n\nExporting plots using walk2 function\nNow we can export a plot for each food security category to a new folder. First we’ll use the here function from the {here} package to create a new folder called plots and a folder within that called slope_plots. We’ll then use the same package to create a pathway through which we can create files for each plot that incorporate the name of the food security category they fit in. Using the walk2 function from the {purrr} package, we can save these plots and specify their dimensions. Why use walk2 instead of map2? The walk family of functions are most useful for calling a function for its side effects (like saving files) rather than its return output (like displaying the plots) (see r4ds for more details).\n\n\nfs::dir_create(here::here(\"plots\", \"slope_plots\"))\nfood_security_groups <- str_replace_all(tolower(fi_plots$security), \" \", \"-\")\npaths <- here::here(\"plots\", \"slope_plots\", glue(\"age_{food_security_groups}.png\"))\n\nwalk2(paths, fi_plots$plot, ggsave,\n      width = 9.5, \n      height = 6.5,\n      dpi = 500)\n\n\n\n\n\n\n",
    "preview": "posts/looping/looping_files/figure-html5/unnamed-chunk-7-1.png",
    "last_modified": "2021-06-11T11:55:17-07:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/writing-functions/",
    "title": "Writing Functions",
    "description": "This is a tutorial for how to write your first custom function in R.",
    "author": [
      {
        "name": "Sarah Dimakis",
        "url": {}
      }
    ],
    "date": "2021-05-13",
    "categories": [
      "custom functions"
    ],
    "contents": "\n\nContents\nLoad libraries and read in data\nFunctions\nDefault settings\nErrors and warnings\nExample function 1\nExample function 2\nTables\n\n\n\n\nLoad libraries and read in data\nFor this tutorial, you will first need to load tidyverse for data wrangling and kableExtra for tables. Next, I am using rio::import to import the cleaned data file to my environment. Note, you may need to change the file path if your file structure is not the same as mine. Last, I am using mutate and case_when to label the levels of the food_secure variable.\nIf you would like to copy the code, you can hover of the code, and a “copy code” box should appear.\n\n\nlibrary(tidyverse)\nlibrary(kableExtra)\n\ndata <- rio::import(here::here(\"data\", \"nhanes_1999-2016.csv\")) %>% \n  mutate(food_security = case_when(hh_food_secure == 1 ~ \"Fully food secure\",\n            hh_food_secure == 2 ~ \"Marginally food secure\",\n            hh_food_secure == 3 ~ \"Food insecure without hunger\",\n            hh_food_secure == 4 ~ \"Food insecure with hunger\"))\n\n\n\nFunctions\nA function is code that carries out an operation. For example + is a function that carries out the operation addition.\n\n\n2 + 3\n\n\n[1] 5\n\nIn algebra, you may recall learning functions such as \\(f(x,y) = x^2+y\\), where you put in inputs x = 2 and y = 1, the function computes the operation, \\(2^2+1\\), and outputs \\(5\\). Similarly, when using a function in R, it takes a form like f(x,y,z..) where f is the function name and x,y,z… are the arguments of the function.\n\n\n`+`(2,3)\n\n\n[1] 5\n\nLet’s create our first function in R called my_pet() that will print out a statement about your pet. For best practice, you should try to name your function something descriptive. It should also not be named another function that is popular like mean because it will overwrite the default mean function for your script.\n\n\nmy_pet <- function(pronoun, animal, verb){\n  paste0(str_to_title(pronoun), \" is a \", animal, \" who likes to \", verb, \".\")\n}\n\n\n\nThe arguments of the function (which are called formals) are what the user supplies the function to get their desired output. You can see the formals of a function in R by using the formals() function.\n\n\nformals(my_pet)\n\n\n$pronoun\n\n\n$animal\n\n\n$verb\n\nThe body of the function is where the function takes in the formals and creates the output. You can see the body of a function in R by using the body() function.\n\n\nbody(my_pet)\n\n\n{\n    paste0(str_to_title(pronoun), \" is a \", animal, \" who likes to \", \n        verb, \".\")\n}\n\nNow, in order to use the function, you can supply it with your desired formals.\n\n\nmy_pet(pronoun = \"she\", \n       animal = \"dog\", \n       verb = \"play outside\")\n\n\n[1] \"She is a dog who likes to play outside.\"\n\nWhen you use your function, you can drop the argument names as long as you keep the same order.\n\n\nmy_pet(\"he\", \"cat\", \"sleep\")\n\n\n[1] \"He is a cat who likes to sleep.\"\n\nIf you want to use arguments out of the order they were defined in, you will need to label them.\n\n\nmy_pet(animal = \"lizard\",\n       pronoun =\"she\", \n       verb = \"eat\")\n\n\n[1] \"She is a lizard who likes to eat.\"\n\nDefault settings\nYou can set a “default” setting for an argument. This is the setting that occurs when the user does not specify the argument.\n\n\nmy_pet2 <- function(pronoun, animal, verb = \"dance\"){\n  paste0(str_to_title(pronoun), \" is a \", animal, \" who likes to \", verb, \".\")\n}\n\n\n\n\n\nmy_pet2(pronoun = \"she\",\n        animal = \"dog\")\n\n\n[1] \"She is a dog who likes to dance.\"\n\nThe user can overwrite the default.\n\n\nmy_pet2(pronoun = \"she\",\n        animal = \"dog\",\n        verb = \"cuddle\")\n\n\n[1] \"She is a dog who likes to cuddle.\"\n\nErrors and warnings\nIf someone else (or your future self) is going to use your function, it is helpful to embed errors with stop() and/or warnings with warning() into your code to explain why the code will not work (or if it will not work as expected).\n\n\n# I am using an if else structure\n# If the user inputs \"cat\" for animal, the function will \n# throw an error and say \"Sorry, this function doesn't work # for people who own cats\"\n# If they use input any other animal, it will work\n\nmy_pet3 <- function(pronoun, animal, verb = \"stretch\"){\n  if(animal == \"cat\"){\n    stop(\"Sorry, this function doesn't work for people who own cats.\")\n  }\n  else{\n    paste0(str_to_title(pronoun), \" is a \", animal, \" who likes to \", verb, \".\")\n    }\n}\n\n\n\n\n\n# This works\nmy_pet3(\"she\", \"dog\")\n\n\n[1] \"She is a dog who likes to stretch.\"\n\n# This throws an error\nmy_pet3(\"he\", \"cat\")\n\n\nError in my_pet3(\"he\", \"cat\"): Sorry, this function doesn't work for people who own cats.\n\nInstead of an error, you might just want to throw a warning, but still allow the function to work.\n\n\nmy_pet4 <- function(pronoun, animal, verb = \"stretch\"){\n  if(animal != \"dog\"){\n    warning(paste0(\"Really? A \", animal, \"? You should really consider getting a dog.\"))\n  }\n  paste0(str_to_title(pronoun), \" is a \", animal, \" who likes to \", verb, \".\")\n    \n}\n\n\n\n\n\nmy_pet4(\"he\", \"cat\")\n\n\nWarning in my_pet4(\"he\", \"cat\"): Really? A cat? You should really\nconsider getting a dog.\n[1] \"He is a cat who likes to stretch.\"\n\nmy_pet4(\"he\", \"fish\", \"swim\")\n\n\nWarning in my_pet4(\"he\", \"fish\", \"swim\"): Really? A fish? You should\nreally consider getting a dog.\n[1] \"He is a fish who likes to swim.\"\n\n# works as normal\nmy_pet4(\"she\", \"dog\")\n\n\n[1] \"She is a dog who likes to stretch.\"\n\nThese are silly examples, but there are many reasons why you would want the function to output a warning or error. For example, you may want the function to warn someone if their input is not going to give them the output they expect, or if the function will not work for certain input. This will help the user work with your function to get their desired output.\nExample function 1\nWhat makes a particularly good function is code that you write a lot. Additionally, you want to make a function that is simple and only does one thing. For this first function, I am going to create a function that will create a “total” column that calculates the total observations across all levels of a grouping variable.\nBefore I create a function, I first like to try to make it work in a single case.\n\n\na <- count(data, year, gender)\na\n\n\n        year gender    n\n1  1999-2000 female 5082\n2  1999-2000   male 4883\n3  2001-2002 female 5708\n4  2001-2002   male 5331\n5  2003-2004 female 5152\n6  2003-2004   male 4970\n7  2005-2006 female 5268\n8  2005-2006   male 5080\n9  2007-2008 female 5053\n10 2007-2008   male 5096\n11 2009-2010 female 5312\n12 2009-2010   male 5225\n13 2011-2012 female 4900\n14 2011-2012   male 4856\n15 2013-2014 female 5172\n16 2013-2014   male 5003\n17 2015-2016 female 5079\n18 2015-2016   male 4892\n\nb <- count(data, year)\nb\n\n\n       year     n\n1 1999-2000  9965\n2 2001-2002 11039\n3 2003-2004 10122\n4 2005-2006 10348\n5 2007-2008 10149\n6 2009-2010 10537\n7 2011-2012  9756\n8 2013-2014 10175\n9 2015-2016  9971\n\n# Join a and b by year\n# There are two n's so I am also changing the suffix of n so that they are labeled more clearly\n\nleft_join(a,b, by = \"year\", \n          suffix = c(\"_group\", \"_total\"))\n\n\n        year gender n_group n_total\n1  1999-2000 female    5082    9965\n2  1999-2000   male    4883    9965\n3  2001-2002 female    5708   11039\n4  2001-2002   male    5331   11039\n5  2003-2004 female    5152   10122\n6  2003-2004   male    4970   10122\n7  2005-2006 female    5268   10348\n8  2005-2006   male    5080   10348\n9  2007-2008 female    5053   10149\n10 2007-2008   male    5096   10149\n11 2009-2010 female    5312   10537\n12 2009-2010   male    5225   10537\n13 2011-2012 female    4900    9756\n14 2011-2012   male    4856    9756\n15 2013-2014 female    5172   10175\n16 2013-2014   male    5003   10175\n17 2015-2016 female    5079    9971\n18 2015-2016   male    4892    9971\n\nNow, let’s try to generalize it.\n\n\ntotal_grouping <- function(data, var, grouping){\n  a <- count(data, var, grouping)\n  b <- count(data, var)\n  c <- left_join(a,b,by = \"year\", \n          suffix = c(\"_group\", \"_total\"))\n}\ntotal_grouping(data, year, gender)\n\n\nError: Must group by variables found in `.data`.\n* Column `var` is not found.\n* Column `grouping` is not found.\n\nUnfortunately, from running this code, we get an error that says that the columns var and grouping are not found. This can happen when you use tidyverse functions to write functions because the tidyverse uses what is called non-standard evaluation. NSE makes the functions really user friendly. For example, when you use dplyr functions like select(data, year) or group_by(data, year), the function knows that year is referring to data$year and not year from your global environment. However, this causes trouble when you try to use select() or group_by() (or in our case, counts()) in your own function. R looks for the column names (in our case, var and grouping) in your global environment but can’t find them. In order to work around this, we need to also use NSE. Here are two ways you can write the function with NSE:\n{{}} Syntax\n\n\ntotal_grouping <- function(data, var, grouping){\n  a <- count(data, {{var}}, {{grouping}}) ##wrap the variables in {{}}\n  b <- count(data, {{var}})\n  left_join(a,b,by = \"year\", \n          suffix = c(\"_group\", \"_total\"))\n}\n\ntotal_grouping(data, year, gender) %>% head()\n\n\n       year gender n_group n_total\n1 1999-2000 female    5082    9965\n2 1999-2000   male    4883    9965\n3 2001-2002 female    5708   11039\n4 2001-2002   male    5331   11039\n5 2003-2004 female    5152   10122\n6 2003-2004   male    4970   10122\n\nQuote the variables\n\n\ntotal_grouping <- function(data, var, grouping){\n  v1 <- enquo(var)  #quote the variables\n  v2 <- enquo(grouping)\n  \n  a <- count(data, !!v1, !!v2) # use !! to evaluate the quoted variables\n  b <- count(data, !!v1)\n  left_join(a,b,by = \"year\", \n          suffix = c(\"_group\", \"_total\"))\n}\n\ntotal_grouping(data, year, gender) %>% head()\n\n\n       year gender n_group n_total\n1 1999-2000 female    5082    9965\n2 1999-2000   male    4883    9965\n3 2001-2002 female    5708   11039\n4 2001-2002   male    5331   11039\n5 2003-2004 female    5152   10122\n6 2003-2004   male    4970   10122\n\nThe great thing about functions is that we can now use our function with other variables, without having to copy,paste, and change the numbers. This cuts down on mistakes and makes your code easier to read.\n\n\ntotal_grouping(data, year, race_ethnic) %>% \n  head()\n\n\n       year        race_ethnic n_group n_total\n1 1999-2000   mexican-american    3393    9965\n2 1999-2000 non-hispanic-black    2228    9965\n3 1999-2000 non-hispanic-white    3367    9965\n4 1999-2000     other-hispanic     589    9965\n5 1999-2000         other-race     388    9965\n6 2001-2002   mexican-american    2776   11039\n\ntotal_grouping(data, year, food_security) %>% \n  head()\n\n\n       year                food_security n_group n_total\n1 1999-2000    Food insecure with hunger     499    9965\n2 1999-2000 Food insecure without hunger    1209    9965\n3 1999-2000            Fully food secure    7102    9965\n4 1999-2000       Marginally food secure     889    9965\n5 1999-2000                         <NA>     266    9965\n6 2001-2002    Food insecure with hunger     627   11039\n\nExample function 2\nYou can use a previous function you have defined earlier in a script in a new function! Here, I am extending the previous function to make a column that will calculate the percentage of the count in a given year.\nLet’s first try an example.\n\n\ntotal_grouping(data, year, gender) %>% \n  mutate(percent = n_group/n_total * 100, #make a new variable called percent \n         percent = round(percent, 2),\n         percent = paste0(percent, \"%\")) #round it and add a % sign\n\n\n        year gender n_group n_total percent\n1  1999-2000 female    5082    9965     51%\n2  1999-2000   male    4883    9965     49%\n3  2001-2002 female    5708   11039  51.71%\n4  2001-2002   male    5331   11039  48.29%\n5  2003-2004 female    5152   10122   50.9%\n6  2003-2004   male    4970   10122   49.1%\n7  2005-2006 female    5268   10348  50.91%\n8  2005-2006   male    5080   10348  49.09%\n9  2007-2008 female    5053   10149  49.79%\n10 2007-2008   male    5096   10149  50.21%\n11 2009-2010 female    5312   10537  50.41%\n12 2009-2010   male    5225   10537  49.59%\n13 2011-2012 female    4900    9756  50.23%\n14 2011-2012   male    4856    9756  49.77%\n15 2013-2014 female    5172   10175  50.83%\n16 2013-2014   male    5003   10175  49.17%\n17 2015-2016 female    5079    9971  50.94%\n18 2015-2016   male    4892    9971  49.06%\n\nOkay, now we’re ready to generalize. Note that I’m using NSE here too.\n\n\npercent_grouping <- function(data, var, grouping){\n  total_grouping(data, {{var}}, {{grouping}}) %>% \n  mutate(percent = n_group/n_total * 100,\n         percent = round(percent, 2),\n         percent = paste0(percent, \"%\")) \n}\n\n\n\n\n\npercent_grouping(data, year, gender) %>% head()\n\n\n       year gender n_group n_total percent\n1 1999-2000 female    5082    9965     51%\n2 1999-2000   male    4883    9965     49%\n3 2001-2002 female    5708   11039  51.71%\n4 2001-2002   male    5331   11039  48.29%\n5 2003-2004 female    5152   10122   50.9%\n6 2003-2004   male    4970   10122   49.1%\n\npercent_grouping(data, year, race_ethnic) %>% head()\n\n\n       year        race_ethnic n_group n_total percent\n1 1999-2000   mexican-american    3393    9965  34.05%\n2 1999-2000 non-hispanic-black    2228    9965  22.36%\n3 1999-2000 non-hispanic-white    3367    9965  33.79%\n4 1999-2000     other-hispanic     589    9965   5.91%\n5 1999-2000         other-race     388    9965   3.89%\n6 2001-2002   mexican-american    2776   11039  25.15%\n\nTables\nNow, let’s make a table with our output. These tables will tell us how the demographics of our sample changed from year to year.\n\n\n# creates an ugly first draft \ntemp_table <- percent_grouping(data, year, gender) %>% \n  select(year, gender, percent) %>% \n  pivot_wider(names_from = gender,\n              values_from = percent) %>% t(.)\n\ntemp_table\n\n\n       [,1]        [,2]        [,3]        [,4]        [,5]       \nyear   \"1999-2000\" \"2001-2002\" \"2003-2004\" \"2005-2006\" \"2007-2008\"\nfemale \"51%\"       \"51.71%\"    \"50.9%\"     \"50.91%\"    \"49.79%\"   \nmale   \"49%\"       \"48.29%\"    \"49.1%\"     \"49.09%\"    \"50.21%\"   \n       [,6]        [,7]        [,8]        [,9]       \nyear   \"2009-2010\" \"2011-2012\" \"2013-2014\" \"2015-2016\"\nfemale \"50.41%\"    \"50.23%\"    \"50.83%\"    \"50.94%\"   \nmale   \"49.59%\"    \"49.77%\"    \"49.17%\"    \"49.06%\"   \n\n# moves the first row to the title\ntable <- temp_table[2:3,]\ncolnames(table) <- temp_table[1,] \nrownames(table) <- rownames(table) %>% str_to_title()\n\n#stylized table\ntable %>% kbl() %>% \n  kable_styling(bootstrap_options = \"striped\", full_width = F)  %>% #gives me a stylized striped table\n  row_spec(0, angle = -45) #rotates column names\n\n\n\n\n\n1999-2000\n\n\n2001-2002\n\n\n2003-2004\n\n\n2005-2006\n\n\n2007-2008\n\n\n2009-2010\n\n\n2011-2012\n\n\n2013-2014\n\n\n2015-2016\n\n\nFemale\n\n\n51%\n\n\n51.71%\n\n\n50.9%\n\n\n50.91%\n\n\n49.79%\n\n\n50.41%\n\n\n50.23%\n\n\n50.83%\n\n\n50.94%\n\n\nMale\n\n\n49%\n\n\n48.29%\n\n\n49.1%\n\n\n49.09%\n\n\n50.21%\n\n\n49.59%\n\n\n49.77%\n\n\n49.17%\n\n\n49.06%\n\n\nI can generalize this with a function so I can make tables for other variables!\n\n\nmy_table <- function(data, var, grouping){\n  temp_table <- percent_grouping(data, {{var}}, {{grouping}}) %>% \n    select({{var}}, {{grouping}}, percent) %>% \n    pivot_wider(names_from = {{grouping}},\n                values_from = percent) %>% t(.)\n  \n  table <- temp_table[2:nrow(temp_table),]\n  colnames(table) <- temp_table[1,] \n  rownames(table) <- rownames(table) %>% str_to_title()\n  \n  table %>% kbl() %>% \n    kable_styling(bootstrap_options = \"striped\", full_width = F) %>% \n    row_spec(0, angle = -45)\n}\n\n\n\n\n\nmy_table(data, year, gender)\n\n\n\n\n\n1999-2000\n\n\n2001-2002\n\n\n2003-2004\n\n\n2005-2006\n\n\n2007-2008\n\n\n2009-2010\n\n\n2011-2012\n\n\n2013-2014\n\n\n2015-2016\n\n\nFemale\n\n\n51%\n\n\n51.71%\n\n\n50.9%\n\n\n50.91%\n\n\n49.79%\n\n\n50.41%\n\n\n50.23%\n\n\n50.83%\n\n\n50.94%\n\n\nMale\n\n\n49%\n\n\n48.29%\n\n\n49.1%\n\n\n49.09%\n\n\n50.21%\n\n\n49.59%\n\n\n49.77%\n\n\n49.17%\n\n\n49.06%\n\n\nmy_table(data, year, race_ethnic)\n\n\n\n\n\n1999-2000\n\n\n2001-2002\n\n\n2003-2004\n\n\n2005-2006\n\n\n2007-2008\n\n\n2009-2010\n\n\n2011-2012\n\n\n2013-2014\n\n\n2015-2016\n\n\nMexican-American\n\n\n34.05%\n\n\n25.15%\n\n\n24.89%\n\n\n27.51%\n\n\n21.25%\n\n\n22.63%\n\n\n13.89%\n\n\n17%\n\n\n19.27%\n\n\nNon-Hispanic-Black\n\n\n22.36%\n\n\n24.29%\n\n\n26.31%\n\n\n26.19%\n\n\n21.79%\n\n\n18.57%\n\n\n27.5%\n\n\n22.28%\n\n\n21.35%\n\n\nNon-Hispanic-White\n\n\n33.79%\n\n\n41.72%\n\n\n40.83%\n\n\n37.96%\n\n\n40.55%\n\n\n41.95%\n\n\n30.47%\n\n\n36.11%\n\n\n30.75%\n\n\nOther-Hispanic\n\n\n5.91%\n\n\n4.68%\n\n\n3.37%\n\n\n3.37%\n\n\n11.83%\n\n\n10.75%\n\n\n11.03%\n\n\n9.43%\n\n\n13.12%\n\n\nOther-Race\n\n\n3.89%\n\n\n4.16%\n\n\n4.6%\n\n\n4.97%\n\n\n4.58%\n\n\n6.1%\n\n\n17.11%\n\n\n15.17%\n\n\n15.51%\n\n\nmy_table(data, year, food_security)\n\n\n\n\n\n1999-2000\n\n\n2001-2002\n\n\n2003-2004\n\n\n2005-2006\n\n\n2007-2008\n\n\n2009-2010\n\n\n2011-2012\n\n\n2013-2014\n\n\n2015-2016\n\n\nFood Insecure With Hunger\n\n\n5.01%\n\n\n5.68%\n\n\n6.33%\n\n\n5.83%\n\n\n6.25%\n\n\n7.99%\n\n\n7.98%\n\n\n7.3%\n\n\n9%\n\n\nFood Insecure Without Hunger\n\n\n12.13%\n\n\n11.68%\n\n\n12.17%\n\n\n13.02%\n\n\n13.34%\n\n\n14.87%\n\n\n15.05%\n\n\n14.47%\n\n\n16.53%\n\n\nFully Food Secure\n\n\n71.27%\n\n\n67.97%\n\n\n68.39%\n\n\n69.8%\n\n\n68.25%\n\n\n63.18%\n\n\n62.41%\n\n\n65.41%\n\n\n56.67%\n\n\nMarginally Food Secure\n\n\n8.92%\n\n\n8.5%\n\n\n8.58%\n\n\n10.1%\n\n\n11.31%\n\n\n12.82%\n\n\n14.05%\n\n\n11.63%\n\n\n14.37%\n\n\nNa\n\n\n2.67%\n\n\n6.18%\n\n\n4.53%\n\n\n1.26%\n\n\n0.85%\n\n\n1.14%\n\n\n0.5%\n\n\n1.2%\n\n\n3.43%\n\n\nOver time, as you use your function with different examples, you may want to tweak it. For example, I noticed by using the food security variable that I never explictly removed NAs. You may want to always remove NAs. Or, you can give your user an option to remove NAs or not by creating an argument called “remove.nas” and set it to TRUE to remove NAs by default. Then, if the user wants to see the NAs, they can set it to FALSE.\nAdditionally, I noticed that I made sure that my row names were capitalized, but I didn’t do that for the column names because it wasn’t relevant here (in all my examples the column names were numbers). This is why it is helpful to test your functions under as many different conditions as you can think of!\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-11T09:12:57-07:00",
    "input_file": {}
  }
]
